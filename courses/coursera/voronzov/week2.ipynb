{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week #2\n",
    "## Метрические методы\n",
    "### Выбор числа соседей\n",
    "Метрические методы основаны на гипотезе компактности, суть которой состоит в том, что объекты с похожими признаковыми описаниями имеют похожие значения целевой переменной. Если эта гипотеза верна, то строить прогноз для нового объекта можно на основе близких к нему объектов из обучающей выборки — например, путем усреднения их ответов (для регрессии) или путем выбора наиболее популярного среди них класса (для классификации). Методы такого типа и называются метрическими. Они имеют несколько особенностей:\n",
    "\n",
    "- Процедура обучения, по сути, отсутствует — достаточно лишь запомнить все объекты обучающей выборки\n",
    "- Можно использовать метрику, учитывающую особенности конкретного набора данных — например, наличие категориальных (номинальных) признаков\n",
    "- При правильном выборе метрики и достаточном размере обучающей выборки метрические алгоритмы показывают качество, близкое к оптимальному\n",
    "\n",
    "Метрические методы чувствительны к масштабу признаков — так, если масштаб одного из признаков существенно превосходит масштабы остальных признаков, то их значения практически не будут влиять на ответы алгоритма. Поэтому важно производить масштабирование признаков. Обычно это делается путем вычитания среднего значения признака и деления на стандартное отклонение.\n",
    "\n",
    "Метод k ближайших соседей реализован в классе sklearn.neighbors.KNeighborsClassifier. Основным параметром является n_neighbors, который задает число соседей для построения прогноза.\n",
    "\n",
    "Вам понадобится производить кросс-валидацию по блокам. Кросс-валидация заключается в разделении выборки на m непересекающихся блоков примерно одинакового размера, после чего выполняется m шагов. На i-м шаге i-й блок выступает в качестве тестовой выборки, объединение всех остальных блоков — в качестве обучающей выборки. Соответственно, на каждом шаге алгоритм обучается на некоторой обучающей выборке, после чего вычисляется его качество на тестовой выборке. После выполнения m шагов мы получаем m показателей качества, усреднение которых и дает оценку кросс-валидации. Подробнее вы можете послушать про кросс-валидацию в видео \"Проблема переобучения. Методология решения задач машинного обучения\" из первого модуля, а также почитать на Википедии (на русском или на английском) или в документации scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1     2     3     4    5     6     7     8     9     10    11    12  \\\n",
       "0   1  14.23  1.71  2.43  15.6  127  2.80  3.06  0.28  2.29  5.64  1.04  3.92   \n",
       "1   1  13.20  1.78  2.14  11.2  100  2.65  2.76  0.26  1.28  4.38  1.05  3.40   \n",
       "2   1  13.16  2.36  2.67  18.6  101  2.80  3.24  0.30  2.81  5.68  1.03  3.17   \n",
       "\n",
       "     13  \n",
       "0  1065  \n",
       "1  1050  \n",
       "2  1185  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загрузите выборку Wine по адресу\n",
    "# https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\n",
    "data = pd.read_csv('data/wine.csv', header=None)\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Извлеките из данных признаки и классы. Класс записан в первом столбце (три варианта), \n",
    "# признаки — в столбцах со второго по последний. Более подробно о сути признаков можно \n",
    "# прочитать по адресу https://archive.ics.uci.edu/ml/datasets/Wine (см. также файл wine.names,\n",
    "# приложенный к заданию)\n",
    "X = data.ix[:,1:]\n",
    "y = data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Оценку качества необходимо провести методом кросс-валидации по 5 блокам (5-fold). \n",
    "# Создайте генератор разбиений, который перемешивает выборку перед формированием блоков \n",
    "# (shuffle=True). Для воспроизводимости результата, создавайте генератор KFold с фиксированным \n",
    "# параметром random_state=42. В качестве меры качества используйте долю верных ответов \n",
    "# (accuracy).\n",
    "# Создается генератор разбиений sklearn.model_selection.KFold, который задает набор разбиений \n",
    "# на обучение и валидацию. Число блоков в кросс-валидации определяется параметром n_folds. \n",
    "# Обратите внимание, что порядок следования объектов в выборке может быть неслучайным, \n",
    "# это может привести к смещенности кросс-валидационной оценки. Чтобы устранить такой эффект, \n",
    "# объекты выборки случайно перемешивают перед разбиением на блоки. Для перемешивания \n",
    "# достаточно передать генератору KFold параметр shuffle=True.\n",
    "kf = KFold(shuffle=True, n_splits=5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=1 acc=0.730476190476\n"
     ]
    }
   ],
   "source": [
    "# Вычислить качество на всех разбиениях можно при помощи функции \n",
    "# sklearn.model_selection.cross_val_score. В качестве параметра estimator передается \n",
    "# классификатор, в качестве параметра cv — генератор разбиений с предыдущего шага. \n",
    "# С помощью параметра scoring можно задавать меру качества, по умолчанию в задачах \n",
    "# классификации используется доля верных ответов (accuracy). Результатом является массив, \n",
    "# значения которого нужно усреднить.\n",
    "# accs = np.empty([0,2], dtype=[('k', float), ('accuracy', float)])\n",
    "k = -1\n",
    "max_acc = 0.\n",
    "for i in range(1,51):\n",
    "    method = KNeighborsClassifier(n_neighbors=i)\n",
    "    acc = np.average(cross_val_score(estimator=method, X=X, y=y, cv=kf))\n",
    "    if max_acc < acc:\n",
    "        max_acc = acc\n",
    "        k = i\n",
    "\n",
    "print 'k={} acc={}'.format(k, max_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Произведите масштабирование признаков с помощью функции sklearn.preprocessing.scale. \n",
    "# Снова найдите оптимальное k на кросс-валидации.\n",
    "# Приведение признаков к одному масштабу можно делать с помощью функции \n",
    "# sklearn.preprocessing.scale, которой на вход необходимо подать матрицу признаков \n",
    "# и получить масштабированную матрицу, в которой каждый столбец имеет нулевое среднее значение \n",
    "# единичное стандартное отклонение.\n",
    "X = scale(data.ix[:,1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=29 acc=0.977619047619\n"
     ]
    }
   ],
   "source": [
    "# Какое значение k получилось оптимальным после приведения признаков к одному масштабу? \n",
    "# Приведите ответы на вопросы 3 и 4. Помогло ли масштабирование признаков?\n",
    "k = -1\n",
    "max_acc = 0.\n",
    "for i in range(1,51):\n",
    "    method = KNeighborsClassifier(n_neighbors=i)\n",
    "    acc = np.average(cross_val_score(estimator=method, X=X, y=y, cv=kf))\n",
    "    if max_acc < acc:\n",
    "        max_acc = acc\n",
    "        k = i\n",
    "\n",
    "print 'k={} acc={}'.format(k, max_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выбор метрики\n",
    "\n",
    "Главным параметром любого метрического алгоритма является функция расстояния (или метрика), используемая для измерения сходства между объектами. Можно использовать стандартный вариант (например, евклидову метрику), но гораздо более эффективным вариантом является подбор метрики под конкретную задачу. Один из подходов — использование той же евклидовой метрики, но с весами: каждой координате ставится в соответствие определенный коэффициент; чем он больше, тем выше вклад признака в итоговое расстояние. Веса настраиваются с целью оптимизации качества на отложенной выборке. Другой подход, о котором и пойдет речь в данном задании — выбор метрики из некоторого класса метрик. Мы возьмем за основу метрику Минковского:\n",
    "dist(x,z)=(sum(xj-zi)^p)^1/p\n",
    "Параметром метрики Минковского является число p, которое мы и будем настраивать.\n",
    "\n",
    "Нам понадобится решать задачу регрессии с помощью метода k ближайших соседей — воспользуйтесь для этого классом sklearn.neighbors.KNeighborsRegressor. Метрика задается с помощью параметра metric, нас будет интересовать значение ’minkowski’. Параметр метрики Минковского задается с помощью параметра p данного класса.\n",
    "\n",
    "Мы будем использовать в данном задании набор данных Boston, где нужно предсказать стоимость жилья на основе различных характеристик расположения (загрязненность воздуха, близость к дорогам и т.д.). Подробнее о признаках можно почитать по адресу https://archive.ics.uci.edu/ml/datasets/Housing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Загрузите выборку Boston с помощью функции sklearn.datasets.load_boston(). \n",
    "# Результатом вызова данной функции является объект, у которого признаки записаны в поле data, \n",
    "# а целевой вектор — в поле target.\n",
    "ds = datasets.load_boston()\n",
    "X = ds.data\n",
    "y = ds.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Приведите признаки в выборке к одному масштабу при помощи функции \n",
    "# sklearn.preprocessing.scale.\n",
    "X = scale(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Переберите разные варианты параметра метрики p по сетке от 1 до 10 с таким шагом, \n",
    "# чтобы всего было протестировано 200 вариантов (используйте функцию numpy.linspace). \n",
    "# Качество оценивайте, как и в предыдущем задании, с помощью кросс-валидации по 5 блокам \n",
    "# с random_state = 42, не забудьте включить перемешивание выборки (shuffle=True).\n",
    "kf = KFold(shuffle=True, n_splits=5, random_state=42)\n",
    "ps = np.linspace(1, 10, num=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p=1.0 acc=-16.0502085084\n"
     ]
    }
   ],
   "source": [
    "# Используйте KNeighborsRegressor с n_neighbors=5 и weights='distance' — данный параметр \n",
    "# добавляет в алгоритм веса, зависящие от расстояния до ближайших соседей. \n",
    "# В качестве метрики качества используйте среднеквадратичную ошибку \n",
    "# (параметр scoring='mean_squared_error' у cross_val_score; при использовании библиотеки \n",
    "# scikit-learn версии 0.18.1 и выше необходимо указывать scoring='neg_mean_squared_error'). \n",
    "# Определите, при каком p качество на кросс-валидации оказалось оптимальным. \n",
    "# Обратите внимание, что cross_val_score возвращает массив показателей качества по блокам; \n",
    "# необходимо максимизировать среднее этих показателей. \n",
    "# Это значение параметра и будет ответом на задачу.\n",
    "max_p = -1\n",
    "max_acc = -float('inf')\n",
    "for p in ps:\n",
    "    method = KNeighborsRegressor(n_neighbors=5, weights='distance', metric='minkowski', p=p)\n",
    "    acc = np.average(cross_val_score(estimator=method, X=X, y=y, cv=kf, \n",
    "                                     scoring='neg_mean_squared_error'))\n",
    "    if max_acc < acc:\n",
    "        max_acc = acc\n",
    "        max_p = p\n",
    "\n",
    "print 'p={} acc={}'.format(max_p, max_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Линейные методы классификации\n",
    "### Нормализация признаков\n",
    "Линейные алгоритмы — распространенный класс моделей, которые отличается своей простотой и скоростью работы. Их можно обучать за разумное время на очень больших объемах данных, и при этом они могут работать с любыми типами признаков — вещественными, категориальными, разреженными. В этом задании мы предлагаем вам воспользоваться персептроном — одним из простейших вариантов линейных моделей.\n",
    "\n",
    "Как и в случае с метрическими методами, качество линейных алгоритмов зависит от некоторых свойств данных. В частности, признаки должны быть нормализованы, то есть иметь одинаковый масштаб. Если это не так, и масштаб одного признака сильно превосходит масштаб других, то качество может резко упасть.\n",
    "\n",
    "Один из способов нормализации заключается в стандартизации признаков. Для этого берется набор значений признака на всех объектах, вычисляется их среднее значение и стандартное отклонение. После этого из всех значений признака вычитается среднее, и затем полученная разность делится на стандартное отклонение.\n",
    "\n",
    "В библиотеке scikit-learn линейные методы реализованы в пакете sklearn.linear_model. Мы будем работать с реализацией персептрона sklearn.linear_model.Perceptron. Как и у большинства моделей, обучение производится с помощью функции fit, построение прогнозов — с помощью функции predict.\n",
    "\n",
    "Пример использования:\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "X = np.array([[1, 2], [3, 4], [5, 6]])\n",
    "\n",
    "y = np.array([0, 1, 0])\n",
    "\n",
    "clf = Perceptron()\n",
    "\n",
    "clf.fit(X, y)\n",
    "\n",
    "predictions = clf.predict(X)\n",
    "\n",
    "В качестве метрики качества мы будем использовать долю верных ответов (accuracy). Для ее подсчета можно воспользоваться функцией sklearn.metrics.accuracy_score, первым аргументом которой является вектор правильных ответов, а вторым — вектор ответов алгоритма.\n",
    "\n",
    "Для стандартизации признаков удобно воспользоваться классом sklearn.preprocessing.StandardScaler. Функция fit_transform данного класса находит параметры нормализации (средние и дисперсии каждого признака) по выборке, и сразу же делает нормализацию выборки с использованием этих параметров. Функция transform делает нормализацию на основе уже найденных параметров.\n",
    "\n",
    "Пример использования:\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = np.array([[100.0, 2.0], [50.0, 4.0], [70.0, 6.0]])\n",
    "\n",
    "X_test = np.array([[90.0, 1], [40.0, 3], [60.0, 4]])\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Загрузите обучающую и тестовую выборки из файлов perceptron-train.csv и perceptron-test.csv. \n",
    "# Целевая переменная записана в первом столбце, признаки — во втором и третьем.\n",
    "data = pd.read_csv('data/perceptron-train.csv', header=None)\n",
    "X_train = data.ix[:,1:]\n",
    "y_train = data.ix[:,0]\n",
    "data = pd.read_csv('data/perceptron-test.csv', header=None)\n",
    "X_test = data.ix[:,1:]\n",
    "y_test = data.ix[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron(alpha=0.0001, class_weight=None, eta0=1.0, fit_intercept=True,\n",
       "      n_iter=5, n_jobs=1, penalty=None, random_state=241, shuffle=True,\n",
       "      verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Обучите персептрон со стандартными параметрами и random_state=241.\n",
    "method = Perceptron(random_state=241)\n",
    "method.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy w/o scaling=0.655\n"
     ]
    }
   ],
   "source": [
    "# Подсчитайте качество (долю правильно классифицированных объектов, accuracy) \n",
    "# полученного классификатора на тестовой выборке.\n",
    "predictions = method.predict(X_test)\n",
    "acc = accuracy_score(y_test, predictions)\n",
    "print 'Accuracy w/o scaling={}'.format(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Нормализуйте обучающую и тестовую выборку с помощью класса StandardScaler.\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy w/ scaling=0.845\n"
     ]
    }
   ],
   "source": [
    "# Обучите персептрон на новой выборке. Найдите долю правильных ответов на тестовой выборке.\n",
    "# method = Perceptron(random_state=241)\n",
    "method.fit(X_train_scaled, y_train)\n",
    "predictions_scaled = method.predict(X_test_scaled)\n",
    "acc_scaled = accuracy_score(y_test, predictions_scaled)\n",
    "print 'Accuracy w/ scaling={}'.format(acc_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy diff=0.19\n"
     ]
    }
   ],
   "source": [
    "# Найдите разность между качеством на тестовой выборке после нормализации и качеством до нее. \n",
    "# Это число и будет ответом на задание.\n",
    "print 'Accuracy diff={}'.format(acc_scaled-acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
